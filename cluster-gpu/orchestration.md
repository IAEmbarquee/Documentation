---
icon: bell-concierge
cover: >-
  https://images.unsplash.com/photo-1588007374946-c79543903e8a?crop=entropy&cs=srgb&fm=jpg&ixid=M3wxOTcwMjR8MHwxfHNlYXJjaHw1fHxuZW9uc3xlbnwwfHx8fDE3NDE1NTM2MzB8MA&ixlib=rb-4.0.3&q=85
coverY: 0
---

# Orchestration

L'orchestration dans un cluster GPU d√©di√© √† l'IA g√®re l'allocation des ressources, la r√©partition des t√¢ches et l'ex√©cution efficace des charges de travail. Des outils comme Docker Swarm optimisent l'utilisation des GPU, assurent la scalabilit√© et facilitent le d√©ploiement des mod√®les d'IA distribu√©s.

Ici, nous utilisons une solution maison bas√©e sur la technologie de conteneurisation Docker&#x20;

## R√©servation de machines

1.  Se connecter √† l'adresse suivante : [http://clusteria](http://clusteria/) (il faut √™tre connect√© au [TailNet](connexion.md) du cluster avant !)&#x20;

    <figure><img src="../.gitbook/assets/reserve1.png" alt=""><figcaption></figcaption></figure>
2.  S√©lectionner **une des trois machines** disponibles (il est pr√©f√©rable de s‚Äôen rappeler afin d‚Äô√©viter de prendre la place de quelqu‚Äôun d‚Äôautre)

    <figure><img src="../.gitbook/assets/reserve2.png" alt=""><figcaption></figcaption></figure>
3.  Puis, s√©lectionner un conteneur (la puce verte signifie qu‚Äôil est disponible et qu‚Äôaucun √©tudiant ne travaille dessus)

    <figure><img src="../.gitbook/assets/reserve3.png" alt="" width="315"><figcaption></figcaption></figure>
4.  Mettre son nom d‚Äôutilisateur universitaire et cliquer sur le bouton Reserve. Vous recevrez alors un mot de passe qui permet de s‚Äôauthentifier en SSH. (N‚Äôoubliez pas que la machine a une dur√©e de vie de 8 heures, apr√®s cela **TOUT ce qui n‚Äôa pas √©t√© plac√© dans le stockage persistant est supprim√©**)

    <figure><img src="../.gitbook/assets/reserve4.png" alt="" width="234"><figcaption></figcaption></figure>

{% hint style="info" %}
Le stockage persistant est un volume de 10 GB mont√© sur chaque conteneur √† travers les trois machines. Cela veut dire que tout le monde a acc√®s en lecture et √©criture √† cet espace.
{% endhint %}

## Utilisations des machines

{% hint style="danger" %}
Chaque conteneur est assign√© √† un utilisateur. √âtant donn√© que les machines sont connect√©es au r√©seau de l‚ÄôUniversit√©, la charte informatique de celle-ci s‚Äôy applique.
{% endhint %}

Vous avez deux espaces de travail disponibles :&#x20;

* Soit l‚Äôinterface web de Jupyter Lab, accessible en cliquant sur le bouton <kbd>Open on JupyterLab</kbd> ou √† l‚Äôadresse <kbd>nomdelamachine:8888</kbd>, avec le mot de passe fourni lors de la r√©servation.&#x20;
* Ou bien par Visual Studio Code **(RECOMMAND√â)**, en cliquant sur le bouton <kbd>Open on VSCode</kbd> ou :
  * Ouvrez VSCode.&#x20;
  * Cliquez sur <kbd>Se connecter √†‚Ä¶</kbd> puis <kbd>Se connecter √† l‚Äôh√¥te</kbd> et tapez <kbd>utilisateur@nomdelamachine</kbd> et le mot de passe.&#x20;

{% hint style="success" %}
Voil√†, vous √™tes connect√©s sur la machine distante.&#x20;
{% endhint %}

{% hint style="info" %}
Le dataset GTSRB est situ√© dans /dataset (lecture seule) et le stockage persistant dans /storage. Veuillez ne pas travailler sur le stockage persistant. (Python g√®re tr√®s mal les montages r√©seau)
{% endhint %}

## La machine

Veuillez ne rien installer dessus, m√™me si vous n‚Äôavez pas les droits sudo :)&#x20;

Chaque conteneur vient √©quip√© avec TOUTES les librairies n√©cessaires :&#x20;

* Python 3.11&#x20;
* Tensorflow 2.14&#x20;
* Keras&#x20;
* Torch, TorchVision, TorchAudio&#x20;
* Qualia, QualiaCodeGen&#x20;
* SciKit Learn, SciKit Image&#x20;
* OpenCV&#x20;
* Pandas, NumPy, MatPlotLib&#x20;
* Toutes les biblioth√®ques Nvidia (CUDA, CUDNN, ‚Ä¶)&#x20;

{% hint style="info" %}
Pour voir l‚Äôutilisation de votre GPU : `nvidia-smi`
{% endhint %}

{% hint style="warning" %}
Essayez d‚Äô√™tre raisonnables en termes d‚Äôutilisation m√©moire (batch sizes de 1M üò•üò•üò•, on n'est pas chez OpenAI)
{% endhint %}

Pour √©viter d'√™tre trop glouton sur la VRAM :

```python
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  try:
    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])
  except RuntimeError as e:
    print(e)
```

```python
// Si celle du haut ne marche pas ou pour TF1

from keras.backend.tensorflow_backend import set_session  
config = tf.ConfigProto()  
config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU  
sess = tf.Session(config=config)  
set_session(sess)
```

